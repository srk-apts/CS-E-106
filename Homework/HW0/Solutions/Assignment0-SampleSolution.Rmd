---
title: "CSCI S-106 - Assignment 0 - Sample Solution"
author: "CSCI S-106 Team"
date: "7/1/2019"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
---

This is a sample submission file. It can differ from yours.

## Problem 1

a. 
$$E(X) = \int_{-\infty}^{\infty}xf_x (x)dx  = \int_{0}^{1}xax^{a-1}dx =  a\int_{0}^{1}x^{a}dx =  $$

$$ =_c \frac{a}{a+1} \cdot \left[x^{a+1} \right]_{0}^{1} = \frac{a}{a+1}   $$
$$E(X^2) = \int_{-\infty}^{\infty}x^2f_x (x)dx  = \int_{0}^{1}ax^{a+1}dx =  =_c \frac{a}{a+2} \cdot \left[x^{a+2} \right]_{0}^{1} = \frac{a}{a+2}  $$


$$var(X) = EX^2 - \left(EX\right)^2 = \frac{a}{a+2} - \frac{a^2}{(a+1)^2} = \frac{a}{(a+1)^2(a+2)}$$


b. 

$$EX = \sum_{x=1}^{n} \frac{x}{n} = \frac{1}{n}\sum_{x=1}^{n} x = \frac{1}{n}\cdot \frac{n\cdot(n+1)}{2}=\frac{(n+1)}{2}$$

$$EX^2 = \sum_{x=1}^{n} \frac{x^2}{n} = \frac{1}{n}\sum_{x=1}^{n} x^2 = \frac{1}{n}\cdot \frac{n\cdot(n+1)(2n+1)}{6}=\frac{(n+1)(2n+1)}{6}$$
$$ var(X) = \frac{(n+1)(2n+1)}{6} - \left(\frac{n+1}{2} \right)^2 = \frac{(n+1)(2n+1)}{6} - \left(\frac{n^2 + 2n +1}{4} \right)^2$$

$$ var(X) = \frac{n^2-1}{12} $$


c. 

$$ E(X) =\int_{-\infty}^{\infty}xf_x (x)dx = \int_{0}^{2}x \frac{3}{2} (x-1)^2dx =\frac{3}{2}
      \int_{0}^{2}(x^3-2x^2 +x)dx = 1 $$

$$ E(X)^2 = \int_{-\infty}^{\infty}x^2f_x (x)dx = \int_{0}^{2}x^2 \frac{3}{2} (x-1)^2dx =\frac{3}{2}
      \int_{0}^{2}(x^4-2x^3 +x^2)dx = \frac{8}{5}$$

$$var(X) = \frac{8}{5}- 1^2 = \frac{3}{5}$$


## Problem 2

There is many possible solutions. Since $N(0,1) ^2 \sim Chi-square(1)$, we can apply to this case.  

Distribution of $ X_1 - X_2$ is $N(0,2)$, thus the distribution of $\frac{X_1 - X_2}{\sqrt{2}}$ is $N(0,1)$. Now, when we square the last random variable, we get the distribution to be central Chi-square with one degree of freedom.


## Problem 3

Make transformations 

$$ y_1 = \frac{x_1}{x_1+x_2}, y_2 = x_1 + x_2 $$

then 

$$x_1 = y_1\cdot y_2, x2 = y_2(1-y_1)$$ 

and Jacobian $$|J| = y_2$$

then 

$$ f(x_1,x_2) =  \left[ \frac{\Gamma(\alpha_1+\alpha_2)}{\Gamma(\alpha_1)\Gamma(\alpha_2)} y_1^{\alpha_1 - 1}\left(1 - y_1\right){}^{\alpha_2}  \right] \left[ \frac{1}{\Gamma(\alpha_1)\Gamma(\alpha_2)} y_1^{\alpha_1 + \alpha_2 - 1}e^{-y_2}  \right] $$
Therefore, $Y_1$ and $Y_2$ are independent.


## Problem 4

$$  L(\alpha, \beta|x) = \left( \frac{\beta^\alpha}{\Gamma(\alpha)}x_1^{\alpha -1}e^{-\beta x_1}\right)
                      \ldots \left( \frac{\beta^\alpha}{\Gamma(\alpha)}x_n^{\alpha - 1}e^{-\beta x_n}\right)$$
                      
        
$$  \ln L(\alpha, \beta|x) = n\alpha \ln \beta - n \ln \Gamma \alpha + (\alpha -1) \sum_{n=1}^{n} \ln x_n - \beta \sum_{n=1}^{n} x_n$$
 
 Set the derivative it to zero
 
  $$\frac{\partial}{\partial \beta}\left(lnLP(\alpha, \beta|x) \right)
        = \frac{\partial}{\partial \beta}\left(n\alpha ln\beta - nln\Gamma \alpha + (\alpha -1)\sum_{n=1}^{n}lnx_n - \beta \sum_{n=1}^{n} x_n \right) = 0 $$
        
        


$$  \frac{n\alpha}{\beta} - \sum_{n=1}^{n} x_n = 0 $$

$$  \frac{n\alpha}{\beta} = \sum_{n=1}^{n} x_n $$
 $$ \hat{\beta}= \frac{n\hat{\alpha}}{\sum_{n=1}^{n} x_n}$$
 

Now we have to show the second derivative is negative in $\hat{\beta}$.

$$ \frac{\partial^2}{\partial \beta^2}\left(lnLP(\alpha, \beta|x) \right) =\frac{\partial}{\partial \beta} \frac{n\alpha}{\beta} - \sum_{n=1}^{n} x_n =  - \frac{n\alpha}{\beta^2} <0 $$, so we have MLE estimator.

Also, this depends on your definition of Gamma distibution ($\beta^\alpha$ in the denominator). You can also have a little bit different solution.  

## Problem 5

$$f(x|\theta) = \theta X^{-2}, \, 0 < \theta \le x < \infty$$
$$L(\theta|x) = \theta^n \left(\prod_i x_i^{-2} \right)I_{[0,\infty)}(x_{(1)})$$



This problem tests whether you understand how to find the optimal solution in corner cases. In those cases derivative in classic sense does not exist, and you need to find the closest solution. 

$$ \hat{\theta} = x_{(1)}$$ where $x_(n)$ is $n$-th highest value.


## Problem 6

```{r setup}
X <- matrix(c(10,1,9,3,8,7,5,2,4), nrow=3, ncol=3, byrow = TRUE) 
X
Y <-  matrix(c(2,8,3,5,1,12,13,4,7), nrow=3, ncol=3, byrow = TRUE) 
Y  
```

For matrix $X$ and $Y$ above, calculate $(X + Y)$

```{r a8}

X + Y

```

## Problem 7

For matrix $X$ and $Y$ above, calculate $(X^TX)^{-1}X^TY$

```{r a9}

solve(t(X)%*%X)%*%(t(X)%*%Y)

```

Note that `t(X)%*%X` can be also solved by function `crossprod(X)` and `t(X)%*%Y` by `crossprod(X,Y)`.

## Problem 8

Write R code to draw $10,000$ random samples from uniform distribution and calculate the $99\%$ percentile.

```{r a10}
set.seed(12345)
quantile(runif(10000),.99)
```


